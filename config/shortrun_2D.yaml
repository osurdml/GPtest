GP_params:
  rel_likelihood: PrefProbit        # Relative likelihood function (in GPpref)
  abs_likelihood: OrdinalProbit     # Absolute likelihood function (AbsBoundProbit or OrdinalProbit)
  verbose: 0                        # Verbosity level
  hyper_counts: [3, 1, 2]           # Number of hypers for GP cov, rel likelihood, abs likelihood
# Hyperparameters are: [l, sig_f, sig_rel, sig_beta, v_beta]
# hyperparameters: [0.012, 1.0, 0.1, 1.0, 35.0]
# abs_obs_params: {sigma: 1.0, v: 35.0}             # Beta distribution parameters
hyperparameters: [0.12, 0.12, 1.0, 0.1, 0.4, 1.2]
abs_obs_params: {sigma: 0.4, b: 1.2, n_ordinals: 7} # Ordinal logistic parameters
rel_obs_params: {sigma: 0.1}                        # Relative logistic parameters
wave_params:
  amp_range: [-1.0, 1.5]
  damp_range: [10.0, 30.0]
  f_range: [2.0, 5.0]
  n_components: 2
  off_range: [0.01, 0.99]
statrun_params:
  n_queries: 30
  n_trials: 100
  n_rel_train: 0
  n_abs_train: 1
  randseed: 1
  n_best_points: 30
  n_xtest: 200
  calc_relative_error: True
  n_rel_samples: 4
# High tau for softmax is more random
learners:
  - name: Random (rel)
    model_type: ActiveLearner
    obs_args: {p_rel: 1.0, n_rel_samples: 4}
  - name: Random (abs)
    model_type: ActiveLearner
    obs_args: {p_rel: 0.0, n_rel_samples: 4}
  - name: Random ($p_{rel}=0.5$)
    model_type: ActiveLearner
    obs_args: {p_rel: 0.5, n_rel_samples: 4}
  - name: MaxVar (abs)
    model_type: MaxVar
    obs_args: {p_rel: 0.0}
  - name: HUCB ($p_{rel}=-1.0, w_v=0.75, \tau_r=0.1, \tau_a=0.05$) (rel, abs)
    model_type: MaxVar
    obs_args: {n_rel_samples: 4, p_rel: -1.0, rel_tau: 0.1, abs_tau: 0.05, w_v: 0.75, selector: entropy}
  - name: Ordinal optimist
    model_type: OrdinalOptimist
    obs_args: {y_threshold: 6, n_rel_samples: 4, p_pref_tol: 1.0e-4}    
